{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2835f5",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    "\n",
    "The goal of this problem is to predict the Annual Turnover of a restaurant based on the variables provided in the data set. \n",
    "\n",
    "**Metric to measure:**\n",
    "\n",
    "The measure of accuracy will be RMSE (Root mean square error)\n",
    "\n",
    "The predicted Annual Turnover for each restaurant in the Test dataset will be compared with the actual Annual Turnover to calculate the RMSE value of the entire prediction. The lower the RMSE value, the better the model will be.\n",
    "\n",
    "**Submission File Format:**\n",
    "You are to submit a  '.csv' file with exactly 500 entries plus a header row. The file should have exactly two columns\n",
    "\n",
    "1.    Registration Number\n",
    "2.    Annual Turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75a7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6cf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_dataset_(2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b64d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registration Number</th>\n",
       "      <th>Annual Turnover</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>City</th>\n",
       "      <th>Restaurant Location</th>\n",
       "      <th>Opening Day of Restaurant</th>\n",
       "      <th>Facebook Popularity Quotient</th>\n",
       "      <th>Endorsed By</th>\n",
       "      <th>Instagram Popularity Quotient</th>\n",
       "      <th>Fire Audit</th>\n",
       "      <th>...</th>\n",
       "      <th>Overall Restaurant Rating</th>\n",
       "      <th>Live Music Rating</th>\n",
       "      <th>Comedy Gigs Rating</th>\n",
       "      <th>Value Deals Rating</th>\n",
       "      <th>Live Sports Rating</th>\n",
       "      <th>Ambience</th>\n",
       "      <th>Lively</th>\n",
       "      <th>Service</th>\n",
       "      <th>Comfortablility</th>\n",
       "      <th>Privacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "      <td>42000000</td>\n",
       "      <td>indian,irish</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Near Business Hub</td>\n",
       "      <td>14/02/09</td>\n",
       "      <td>84.30</td>\n",
       "      <td>Not Specific</td>\n",
       "      <td>95.80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "      <td>50000000</td>\n",
       "      <td>indian,irish</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>29/09/08</td>\n",
       "      <td>85.40</td>\n",
       "      <td>Tier A Celebrity</td>\n",
       "      <td>85.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "      <td>32500000</td>\n",
       "      <td>tibetan,italian</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Near Business Hub</td>\n",
       "      <td>30/07/11</td>\n",
       "      <td>85.00</td>\n",
       "      <td>Tier A Celebrity</td>\n",
       "      <td>68.20</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "      <td>110000000</td>\n",
       "      <td>turkish,nigerian</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>30/11/08</td>\n",
       "      <td>85.60</td>\n",
       "      <td>Tier A Celebrity</td>\n",
       "      <td>83.60</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "      <td>20000000</td>\n",
       "      <td>irish,belgian</td>\n",
       "      <td>Manesar</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>22/02/10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier A Celebrity</td>\n",
       "      <td>76.80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>63489</td>\n",
       "      <td>40500000</td>\n",
       "      <td>algerian,belgian</td>\n",
       "      <td>-1</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>20/03/09</td>\n",
       "      <td>69.10</td>\n",
       "      <td>Not Specific</td>\n",
       "      <td>62.11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>63490</td>\n",
       "      <td>32500000</td>\n",
       "      <td>tibetan,greek</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>05/02/12</td>\n",
       "      <td>91.00</td>\n",
       "      <td>Not Specific</td>\n",
       "      <td>96.30</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>63491</td>\n",
       "      <td>42500000</td>\n",
       "      <td>indian,irish</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>21/05/09</td>\n",
       "      <td>80.83</td>\n",
       "      <td>Not Specific</td>\n",
       "      <td>86.80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>63492</td>\n",
       "      <td>53000000</td>\n",
       "      <td>japanese,thai</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>22/06/08</td>\n",
       "      <td>79.40</td>\n",
       "      <td>Not Specific</td>\n",
       "      <td>86.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>63493</td>\n",
       "      <td>12000000</td>\n",
       "      <td>indian,irish</td>\n",
       "      <td>Ghaziabad</td>\n",
       "      <td>Near Party Hub</td>\n",
       "      <td>23/04/09</td>\n",
       "      <td>72.00</td>\n",
       "      <td>Not Specific</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3493 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Registration Number  Annual Turnover           Cuisine        City  \\\n",
       "0                   60001         42000000      indian,irish   Bangalore   \n",
       "1                   60002         50000000      indian,irish      Indore   \n",
       "2                   60003         32500000   tibetan,italian     Chennai   \n",
       "3                   60004        110000000  turkish,nigerian     Gurgaon   \n",
       "4                   60005         20000000     irish,belgian     Manesar   \n",
       "...                   ...              ...               ...         ...   \n",
       "3488                63489         40500000  algerian,belgian          -1   \n",
       "3489                63490         32500000     tibetan,greek  Bangalore    \n",
       "3490                63491         42500000      indian,irish     Chennai   \n",
       "3491                63492         53000000     japanese,thai   Bangalore   \n",
       "3492                63493         12000000      indian,irish   Ghaziabad   \n",
       "\n",
       "     Restaurant Location Opening Day of Restaurant  \\\n",
       "0      Near Business Hub                  14/02/09   \n",
       "1         Near Party Hub                  29/09/08   \n",
       "2      Near Business Hub                  30/07/11   \n",
       "3         Near Party Hub                  30/11/08   \n",
       "4         Near Party Hub                  22/02/10   \n",
       "...                  ...                       ...   \n",
       "3488      Near Party Hub                  20/03/09   \n",
       "3489      Near Party Hub                  05/02/12   \n",
       "3490      Near Party Hub                  21/05/09   \n",
       "3491      Near Party Hub                  22/06/08   \n",
       "3492      Near Party Hub                  23/04/09   \n",
       "\n",
       "      Facebook Popularity Quotient       Endorsed By  \\\n",
       "0                            84.30      Not Specific   \n",
       "1                            85.40  Tier A Celebrity   \n",
       "2                            85.00  Tier A Celebrity   \n",
       "3                            85.60  Tier A Celebrity   \n",
       "4                              NaN  Tier A Celebrity   \n",
       "...                            ...               ...   \n",
       "3488                         69.10      Not Specific   \n",
       "3489                         91.00      Not Specific   \n",
       "3490                         80.83      Not Specific   \n",
       "3491                         79.40      Not Specific   \n",
       "3492                         72.00      Not Specific   \n",
       "\n",
       "      Instagram Popularity Quotient  Fire Audit  ...  \\\n",
       "0                             95.80           1  ...   \n",
       "1                             85.00           1  ...   \n",
       "2                             68.20           1  ...   \n",
       "3                             83.60           0  ...   \n",
       "4                             76.80           1  ...   \n",
       "...                             ...         ...  ...   \n",
       "3488                          62.11           1  ...   \n",
       "3489                          96.30           1  ...   \n",
       "3490                          86.80           1  ...   \n",
       "3491                          86.00           1  ...   \n",
       "3492                          67.00           1  ...   \n",
       "\n",
       "      Overall Restaurant Rating  Live Music Rating  Comedy Gigs Rating  \\\n",
       "0                          10.0                4.0                 NaN   \n",
       "1                           9.0                NaN                 4.0   \n",
       "2                           8.0                3.0                 NaN   \n",
       "3                           9.0                6.0                 NaN   \n",
       "4                           6.0                NaN                 2.0   \n",
       "...                         ...                ...                 ...   \n",
       "3488                        9.0                5.0                 NaN   \n",
       "3489                        NaN                4.0                 NaN   \n",
       "3490                        8.0                NaN                 NaN   \n",
       "3491                        7.0                3.0                 2.0   \n",
       "3492                        NaN                1.0                 NaN   \n",
       "\n",
       "      Value Deals Rating  Live Sports Rating Ambience Lively  Service  \\\n",
       "0                    NaN                 NaN      8.0      8        6   \n",
       "1                    NaN                 NaN      5.0      7        7   \n",
       "2                    NaN                 NaN      7.0     10        5   \n",
       "3                    NaN                 NaN      7.0      7        4   \n",
       "4                    NaN                 NaN      NaN      6        2   \n",
       "...                  ...                 ...      ...    ...      ...   \n",
       "3488                 NaN                 NaN      7.0      7        6   \n",
       "3489                 NaN                 NaN      4.0      9        4   \n",
       "3490                 NaN                 3.0      6.0      8        3   \n",
       "3491                 NaN                 NaN      7.0      6        3   \n",
       "3492                 NaN                 NaN      6.0      9        6   \n",
       "\n",
       "      Comfortablility  Privacy  \n",
       "0                   6        6  \n",
       "1                   3        8  \n",
       "2                   2        8  \n",
       "3                   3        5  \n",
       "4                   4        6  \n",
       "...               ...      ...  \n",
       "3488                6        8  \n",
       "3489                0        5  \n",
       "3490                3        7  \n",
       "3491                3        6  \n",
       "3492                3        8  \n",
       "\n",
       "[3493 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849b4e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess(df):\n",
    "    \n",
    "    \n",
    "    cuisines = ['indian', \"irish\", \"tibetan\", \"italian\", \"turkish\", \"nigerian\", \"belgian\", \"greek\", \"chinese\", \"salvadorian\", \n",
    "            \"algerian\", \"welsh\", \"thai\", \"peruvian\", \"cuban\", \"japanese\", \"british\", \"nigerian\", \"cajun\", \"polish\", \"jewish\",\n",
    "           \"korean\", \"swedish\", \"sapnish\", \"hawaiian\", \"latvian\"]\n",
    "    \n",
    "    cities = ['Bangalore', 'Noida', 'Hyderabad', 'Pune', 'Chennai', 'Gurgaon']\n",
    "    \n",
    "    celeb_dict = {'Tier A Celebrity':2, 'Local Celebrity':1, 'Not Specific':0}\n",
    "    \n",
    "    type_ = ['Bar', 'Caffee', 'Gastro Bar']\n",
    "    \n",
    "    th = ['Arabian', 'Greek', \"90's\"]\n",
    "    \n",
    "    for cuisine in cuisines:\n",
    "        df[\"cui_\"+cuisine] = df[\"Cuisine\"].apply(lambda x: 1 if cuisine in x.lower() else 0)\n",
    "        \n",
    "    for city in cities:\n",
    "        df[\"city_\"+city] = df[\"City\"].apply(lambda x: 1 if x == city else 0)\n",
    "        \n",
    "    df[\"Restaurant Location\"] = df[\"Restaurant Location\"].apply(lambda x: 1 if x==\"Near Business Hub\" else 0)\n",
    "    \n",
    "    df[\"Endorsed By\"].replace(celeb_dict, inplace=True)\n",
    "    \n",
    "    df[\"Opening Day of Restaurant\"]=(pd.to_datetime('2016-05-22 00:00:00')-pd.to_datetime(df[\"Opening Day of Restaurant\"])).dt.days\n",
    "    \n",
    "    df[\"Facebook Popularity Quotient\"].fillna(0, inplace=True)\n",
    "    \n",
    "    df[\"Instagram Popularity Quotient\"].fillna(0, inplace=True)\n",
    "    \n",
    "    df[\"Resturant Tier\"].fillna(0, inplace=True)\n",
    "    \n",
    "    for t in type_:\n",
    "        df[\"ty_\"+t] = df[\"Restaurant Type\"].apply(lambda x: 1 if x == t else 0)\n",
    "        \n",
    "    for t in th:\n",
    "        df[\"th_\"+t] = df[\"Restaurant Theme\"].apply(lambda x: 1 if x == t else 0)\n",
    "        \n",
    "    ratings = ['Overall Restaurant Rating', 'Live Music Rating', 'Comedy Gigs Rating',\n",
    "       'Value Deals Rating', 'Live Sports Rating', \"Ambience\"]\n",
    "\n",
    "    for r in ratings:\n",
    "        df[r].fillna(0,inplace=True)\n",
    "        \n",
    "    df.drop(\"Cuisine\", axis=1, inplace=True)\n",
    "    \n",
    "    df.drop(\"City\", axis=1, inplace=True)\n",
    "    \n",
    "    df.drop(\"Restaurant Type\", axis=1, inplace=True)\n",
    "    \n",
    "    df.drop(\"Restaurant Theme\", axis=1, inplace=True)  \n",
    "    \n",
    "    ids = df[\"Registration Number\"]\n",
    "    \n",
    "    df.drop(\"Registration Number\", axis=1, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f444e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"Annual Turnover\", axis=1), df[\"Annual Turnover\"], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d91d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pp = preprocess(X_train)\n",
    "X_test_pp = preprocess(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a7433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df, train=0, sk=None):\n",
    "    if train==1:\n",
    "        a = sk.fit_transform(df)\n",
    "        return a\n",
    "    else:\n",
    "        a = sk.transform(df)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb663370",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = StandardScaler()\n",
    "X_train_scaled = scaling(X_train_pp, 1, sk)\n",
    "X_test_scaled = scaling(X_test_pp, 0, sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d891a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "class model_selection:\n",
    "    \n",
    "    def __init__(self, X, y, X_test, y_test):\n",
    "        self.scores = []\n",
    "        model_names = [\"LR\",\"XGB\",\"DTR\",\"ADB\",\"RIDGE\",\"LASSO\",\"KNN\",\"GBR\",\"SVR\",\"RFR\"]\n",
    "        models = [self.LR(X, y),self.XGB(X, y),self.DTR(X, y),self.ADB(X, y),self.RIDGE(X, y),self.LASSO(X, y),self.KNN(X, y),self.GBR(X, y),self.SVR(X, y),self.RFR(X, y)]\n",
    "        for i in range(len(models)):\n",
    "            print(model_names[i], \"is starting\")\n",
    "            m = models[i]\n",
    "            print(model_names[i], \"is trained\")\n",
    "            self.scores_cal(m, X, y,X_test,y_test, model_names[i])\n",
    "            print(model_names[i], \"is scored\")\n",
    "            \n",
    "            \n",
    "        self.scores_df = pd.DataFrame(self.scores, columns=[\"model\",\"train acc\", \"test acc\", \"train_rmse\", \"test_rmse\"])\n",
    "        self.models_dict = dict(zip(model_names, models))\n",
    "    \n",
    "    def scores_cal(self,m, X, y,X_test,y_test, mn):\n",
    "        print(m)\n",
    "        score = self.metric(m, X, y,X_test,y_test)\n",
    "        score.insert(0, mn)\n",
    "        print(score)\n",
    "        self.scores.append(score)\n",
    "        \n",
    "    def get_scores(self):\n",
    "        return self.scores_df\n",
    "    \n",
    "           \n",
    "    def LR(self, X, y):\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X, y)\n",
    "        return lr\n",
    "\n",
    "    def XGB(self, X, y):\n",
    "        xgb = XGBRegressor(random_state=42)\n",
    "        xgb_params = {\n",
    "                        'n_estimators': [100, 200, 300, 400, 500],\n",
    "                        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "                        'booster': ['gbtree', 'gblinear', 'dart']\n",
    "                    }\n",
    "        bp = self.random_search_cv(xgb, xgb_params, X, y)\n",
    "        return bp\n",
    "\n",
    "\n",
    "    def DTR(self, X, y):\n",
    "        dtr = DecisionTreeRegressor(random_state=42)\n",
    "        dtr_params = {\n",
    "                                'criterion': ['absolute_error', 'poisson', 'squared_error', 'friedman_mse'],\n",
    "                                'splitter': ['best', 'random'],\n",
    "                                'max_depth': [None] + list(range(1, 10)),\n",
    "                                'min_samples_split': list(range(2, 10)),\n",
    "                                'min_samples_leaf': list(range(1, 10))\n",
    "                            }\n",
    "        bp = self.random_search_cv(dtr, dtr_params, X, y)\n",
    "        return bp\n",
    "\n",
    "\n",
    "    def SVR(self, X, y):\n",
    "        svr = SVR()\n",
    "        svr_params = {\n",
    "                        'C': [0.1, 1, 10, 100],\n",
    "                        'kernel': ['rbf'],\n",
    "                        'degree': [2, 3, 4, 5],\n",
    "                        'gamma': ['scale', 'auto'],\n",
    "                        'epsilon': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "                    }\n",
    "        bp = self.random_search_cv(svr, svr_params, X, y)\n",
    "        return bp\n",
    "    \n",
    "    def ADB(self, X, y):\n",
    "        adb = AdaBoostRegressor(random_state=42)\n",
    "        adb_params = {\n",
    "                        'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "                        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "                        'loss': ['linear', 'square', 'exponential']\n",
    "                    }\n",
    "        bp = self.random_search_cv(adb, adb_params, X, y)\n",
    "        return bp\n",
    "\n",
    "        \n",
    "    def RIDGE(self, X, y):\n",
    "        rdg = Ridge()\n",
    "        rdg.fit(X, y)\n",
    "        return rdg\n",
    "        \n",
    "    def LASSO(self, X, y):\n",
    "        lso = LassoCV()\n",
    "        lso.fit(X, y)\n",
    "        return lso\n",
    "        \n",
    "    def KNN(self, X, y):\n",
    "        knn = KNeighborsRegressor()\n",
    "        knn_params = {\n",
    "                        'n_neighbors': list(range(1, 30)),\n",
    "                        'weights': ['uniform', 'distance'],\n",
    "                        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                        'p': [1, 2]\n",
    "                    }\n",
    "        bp = self.random_search_cv(knn, knn_params, X, y)\n",
    "        return bp\n",
    "\n",
    "        \n",
    "    def GBR(self, X, y):\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        \n",
    "        gbr_params = {\n",
    "                        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "                        'n_estimators': [100, 200, 300, 400, 500],\n",
    "                        'max_depth': list(range(1, 10)),\n",
    "                        'min_samples_split': list(range(2, 10)),\n",
    "                        'min_samples_leaf': list(range(1, 10)),\n",
    "                        'max_features': ['sqrt', 'log2']\n",
    "                    }\n",
    "        bp = self.random_search_cv(gbr, gbr_params, X, y)\n",
    "        return bp\n",
    "    \n",
    "    def RFR(self, X, y):\n",
    "        rf = RandomForestRegressor(random_state = 42)\n",
    "        rf_params = {'bootstrap': [True, False],\n",
    "                     'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "                     'max_features': ['log2', 'sqrt'],\n",
    "                     'min_samples_leaf': [1, 2, 4],\n",
    "                     'min_samples_split': [2, 5, 10],\n",
    "                     'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "        bp = self.random_search_cv(rf, rf_params, X, y)\n",
    "        return bp\n",
    "\n",
    "    \n",
    "    def random_search_cv(self, model, params, X, y):\n",
    "        random_search = RandomizedSearchCV(model, param_distributions=params, cv=3, verbose=1,scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "        random_search.fit(X, y)\n",
    "#         print(\"Best Parameters: \",random_search.best_params_)\n",
    "        return random_search.best_estimator_\n",
    "    \n",
    "    def metric(self, model, X, y, X_test, y_test):\n",
    "        print(model)\n",
    "        train_scores = cross_val_score(model, X, y, cv=3)\n",
    "        test_scores = cross_val_score(model, X_test, y_test, cv=3)\n",
    "        train_rmse = mean_squared_error(y, model.predict(X), squared=False)\n",
    "        test_rmse = mean_squared_error(y_test, model.predict(X_test), squared=False)\n",
    "        return [np.mean(train_scores), np.mean(test_scores), train_rmse, test_rmse]\n",
    "    \n",
    "    def get_models(self):\n",
    "        return self.models_dict\n",
    "    \n",
    "    def get_preds(self, m, df):\n",
    "        return self.models_dict[m].predict(df)\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7deb7503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "LR is starting\n",
      "LR is trained\n",
      "LinearRegression()\n",
      "LinearRegression()\n",
      "['LR', 0.08509127272728671, 0.04828296055415715, 20043779.51403427, 19504077.462467767]\n",
      "LR is scored\n",
      "XGB is starting\n",
      "XGB is trained\n",
      "XGBRegressor(base_score=None, booster='gblinear', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "XGBRegressor(base_score=None, booster='gblinear', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "['XGB', 0.07826647033265781, 0.07067932536524683, 20333040.19414333, 19552250.196429588]\n",
      "XGB is scored\n",
      "DTR is starting\n",
      "DTR is trained\n",
      "DecisionTreeRegressor(criterion='absolute_error', max_depth=5,\n",
      "                      min_samples_leaf=9, min_samples_split=8, random_state=42)\n",
      "DecisionTreeRegressor(criterion='absolute_error', max_depth=5,\n",
      "                      min_samples_leaf=9, min_samples_split=8, random_state=42)\n",
      "['DTR', 0.033324405361458455, -0.03170641012487774, 21124130.407677677, 20360394.006108265]\n",
      "DTR is scored\n",
      "ADB is starting\n",
      "ADB is trained\n",
      "AdaBoostRegressor(learning_rate=0.01, random_state=42)\n",
      "AdaBoostRegressor(learning_rate=0.01, random_state=42)\n",
      "['ADB', 0.06683930208470645, 0.0570134254621237, 19948059.41188922, 19983413.402143467]\n",
      "ADB is scored\n",
      "RIDGE is starting\n",
      "RIDGE is trained\n",
      "Ridge()\n",
      "Ridge()\n",
      "['RIDGE', 0.08723528204588549, 0.053483285489067854, 20044777.47064236, 19499404.000705097]\n",
      "RIDGE is scored\n",
      "LASSO is starting\n",
      "LASSO is trained\n",
      "LassoCV()\n",
      "LassoCV()\n",
      "['LASSO', 0.07140869063380222, 0.09033858696315533, 20998186.783772953, 19883432.880974498]\n",
      "LASSO is scored\n",
      "KNN is starting\n",
      "KNN is trained\n",
      "KNeighborsRegressor(algorithm='brute', n_neighbors=25, p=1)\n",
      "KNeighborsRegressor(algorithm='brute', n_neighbors=25, p=1)\n",
      "['KNN', 0.001961562855205027, -0.00982175029010283, 20732711.56689726, 20504165.12332507]\n",
      "KNN is scored\n",
      "GBR is starting\n",
      "GBR is trained\n",
      "GradientBoostingRegressor(max_depth=4, max_features='log2', min_samples_leaf=8,\n",
      "                          min_samples_split=9)\n",
      "GradientBoostingRegressor(max_depth=4, max_features='log2', min_samples_leaf=8,\n",
      "                          min_samples_split=9)\n",
      "['GBR', 0.10167380445088588, 0.02953808157611541, 16920103.84976518, 19281240.189865857]\n",
      "GBR is scored\n",
      "SVR is starting\n",
      "SVR is trained\n",
      "SVR(C=100, degree=4, epsilon=0.2)\n",
      "SVR(C=100, degree=4, epsilon=0.2)\n",
      "['SVR', -0.0016395084237555608, -0.004309617180406973, 21989242.315081216, 20872584.692274224]\n",
      "SVR is scored\n",
      "RFR is starting\n",
      "RFR is trained\n",
      "RandomForestRegressor(max_depth=70, max_features='log2', min_samples_split=5,\n",
      "                      n_estimators=1200, random_state=42)\n",
      "RandomForestRegressor(max_depth=70, max_features='log2', min_samples_split=5,\n",
      "                      n_estimators=1200, random_state=42)\n",
      "['RFR', 0.11417761410323639, 0.11000814767420297, 11842856.816033324, 19255448.273171127]\n",
      "RFR is scored\n"
     ]
    }
   ],
   "source": [
    "model_selector = model_selection(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1ad3db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train acc</th>\n",
       "      <th>test acc</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.085091</td>\n",
       "      <td>0.048283</td>\n",
       "      <td>2.004378e+07</td>\n",
       "      <td>1.950408e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.078266</td>\n",
       "      <td>0.070679</td>\n",
       "      <td>2.033304e+07</td>\n",
       "      <td>1.955225e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTR</td>\n",
       "      <td>0.033324</td>\n",
       "      <td>-0.031706</td>\n",
       "      <td>2.112413e+07</td>\n",
       "      <td>2.036039e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADB</td>\n",
       "      <td>0.066839</td>\n",
       "      <td>0.057013</td>\n",
       "      <td>1.994806e+07</td>\n",
       "      <td>1.998341e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.087235</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>2.004478e+07</td>\n",
       "      <td>1.949940e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.071409</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>2.099819e+07</td>\n",
       "      <td>1.988343e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>-0.009822</td>\n",
       "      <td>2.073271e+07</td>\n",
       "      <td>2.050417e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBR</td>\n",
       "      <td>0.101674</td>\n",
       "      <td>0.029538</td>\n",
       "      <td>1.692010e+07</td>\n",
       "      <td>1.928124e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>-0.001640</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>2.198924e+07</td>\n",
       "      <td>2.087258e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RFR</td>\n",
       "      <td>0.114178</td>\n",
       "      <td>0.110008</td>\n",
       "      <td>1.184286e+07</td>\n",
       "      <td>1.925545e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  train acc  test acc    train_rmse     test_rmse\n",
       "0     LR   0.085091  0.048283  2.004378e+07  1.950408e+07\n",
       "1    XGB   0.078266  0.070679  2.033304e+07  1.955225e+07\n",
       "2    DTR   0.033324 -0.031706  2.112413e+07  2.036039e+07\n",
       "3    ADB   0.066839  0.057013  1.994806e+07  1.998341e+07\n",
       "4  RIDGE   0.087235  0.053483  2.004478e+07  1.949940e+07\n",
       "5  LASSO   0.071409  0.090339  2.099819e+07  1.988343e+07\n",
       "6    KNN   0.001962 -0.009822  2.073271e+07  2.050417e+07\n",
       "7    GBR   0.101674  0.029538  1.692010e+07  1.928124e+07\n",
       "8    SVR  -0.001640 -0.004310  2.198924e+07  2.087258e+07\n",
       "9    RFR   0.114178  0.110008  1.184286e+07  1.925545e+07"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8fa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0de764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "LR is starting\n",
      "LR is trained\n",
      "LinearRegression()\n",
      "LinearRegression()\n",
      "['LR', -7.666398411174068e+17, 0.048438537372777556, 20062335.2017596, 19570629.830787413]\n",
      "LR is scored\n",
      "XGB is starting\n",
      "XGB is trained\n",
      "XGBRegressor(base_score=None, booster='gblinear', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=400, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "XGBRegressor(base_score=None, booster='gblinear', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=400, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "['XGB', 0.08837290437846979, 0.06308801301519917, 20070841.369573083, 19466311.96476747]\n",
      "XGB is scored\n",
      "DTR is starting\n",
      "DTR is trained\n",
      "DecisionTreeRegressor(criterion='absolute_error', max_depth=5,\n",
      "                      min_samples_leaf=9, min_samples_split=8, random_state=42)\n",
      "DecisionTreeRegressor(criterion='absolute_error', max_depth=5,\n",
      "                      min_samples_leaf=9, min_samples_split=8, random_state=42)\n",
      "['DTR', 0.033324405361458455, -0.03054488096766424, 21124130.407677677, 20360394.006108265]\n",
      "DTR is scored\n",
      "ADB is starting\n",
      "ADB is trained\n",
      "AdaBoostRegressor(learning_rate=0.01, random_state=42)\n",
      "AdaBoostRegressor(learning_rate=0.01, random_state=42)\n",
      "['ADB', 0.0649138360321833, 0.056837988699052246, 19912517.817025907, 19970733.11228624]\n",
      "ADB is scored\n",
      "RIDGE is starting\n",
      "RIDGE is trained\n",
      "Ridge()\n",
      "Ridge()\n",
      "['RIDGE', 0.08526793890811357, 0.048929119025628055, 20043800.007105496, 19503536.190730553]\n",
      "RIDGE is scored\n",
      "LASSO is starting\n",
      "LASSO is trained\n",
      "LassoCV()\n",
      "LassoCV()\n",
      "['LASSO', 0.10106666516078928, 0.10596123163368458, 20234424.11171331, 19390290.1649435]\n",
      "LASSO is scored\n",
      "KNN is starting\n",
      "KNN is trained\n",
      "KNeighborsRegressor(algorithm='brute', n_neighbors=25, p=1)\n",
      "KNeighborsRegressor(algorithm='brute', n_neighbors=25, p=1)\n",
      "['KNN', 0.056870814596513185, 0.09194452655951897, 20417246.00021092, 20054971.371646415]\n",
      "KNN is scored\n",
      "GBR is starting\n",
      "GBR is trained\n",
      "GradientBoostingRegressor(max_depth=4, max_features='log2', min_samples_leaf=8,\n",
      "                          min_samples_split=9)\n",
      "GradientBoostingRegressor(max_depth=4, max_features='log2', min_samples_leaf=8,\n",
      "                          min_samples_split=9)\n",
      "['GBR', 0.10395757179076252, 0.026477489740586464, 17073318.990101364, 19377552.63074685]\n",
      "GBR is scored\n",
      "SVR is starting\n",
      "SVR is trained\n",
      "SVR(C=100, degree=4, epsilon=0.2)\n",
      "SVR(C=100, degree=4, epsilon=0.2)\n",
      "['SVR', -0.0016185852549886655, -0.004302413376557383, 21988851.79730317, 20872246.073850945]\n",
      "SVR is scored\n",
      "RFR is starting\n",
      "RFR is trained\n",
      "RandomForestRegressor(max_depth=70, max_features='log2', min_samples_split=5,\n",
      "                      n_estimators=1200, random_state=42)\n",
      "RandomForestRegressor(max_depth=70, max_features='log2', min_samples_split=5,\n",
      "                      n_estimators=1200, random_state=42)\n",
      "['RFR', 0.11447122446773302, 0.11032274679372937, 11841708.08420271, 19259468.378872797]\n",
      "RFR is scored\n"
     ]
    }
   ],
   "source": [
    "model_selector_scaled = model_selection(X_train_scaled, y_train, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee92d293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train acc</th>\n",
       "      <th>test acc</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>-7.666398e+17</td>\n",
       "      <td>0.048439</td>\n",
       "      <td>2.006234e+07</td>\n",
       "      <td>1.957063e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>8.837290e-02</td>\n",
       "      <td>0.063088</td>\n",
       "      <td>2.007084e+07</td>\n",
       "      <td>1.946631e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTR</td>\n",
       "      <td>3.332441e-02</td>\n",
       "      <td>-0.030545</td>\n",
       "      <td>2.112413e+07</td>\n",
       "      <td>2.036039e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADB</td>\n",
       "      <td>6.491384e-02</td>\n",
       "      <td>0.056838</td>\n",
       "      <td>1.991252e+07</td>\n",
       "      <td>1.997073e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>8.526794e-02</td>\n",
       "      <td>0.048929</td>\n",
       "      <td>2.004380e+07</td>\n",
       "      <td>1.950354e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>1.010667e-01</td>\n",
       "      <td>0.105961</td>\n",
       "      <td>2.023442e+07</td>\n",
       "      <td>1.939029e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>5.687081e-02</td>\n",
       "      <td>0.091945</td>\n",
       "      <td>2.041725e+07</td>\n",
       "      <td>2.005497e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBR</td>\n",
       "      <td>1.039576e-01</td>\n",
       "      <td>0.026477</td>\n",
       "      <td>1.707332e+07</td>\n",
       "      <td>1.937755e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>-1.618585e-03</td>\n",
       "      <td>-0.004302</td>\n",
       "      <td>2.198885e+07</td>\n",
       "      <td>2.087225e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RFR</td>\n",
       "      <td>1.144712e-01</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>1.184171e+07</td>\n",
       "      <td>1.925947e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model     train acc  test acc    train_rmse     test_rmse\n",
       "0     LR -7.666398e+17  0.048439  2.006234e+07  1.957063e+07\n",
       "1    XGB  8.837290e-02  0.063088  2.007084e+07  1.946631e+07\n",
       "2    DTR  3.332441e-02 -0.030545  2.112413e+07  2.036039e+07\n",
       "3    ADB  6.491384e-02  0.056838  1.991252e+07  1.997073e+07\n",
       "4  RIDGE  8.526794e-02  0.048929  2.004380e+07  1.950354e+07\n",
       "5  LASSO  1.010667e-01  0.105961  2.023442e+07  1.939029e+07\n",
       "6    KNN  5.687081e-02  0.091945  2.041725e+07  2.005497e+07\n",
       "7    GBR  1.039576e-01  0.026477  1.707332e+07  1.937755e+07\n",
       "8    SVR -1.618585e-03 -0.004302  2.198885e+07  2.087225e+07\n",
       "9    RFR  1.144712e-01  0.110323  1.184171e+07  1.925947e+07"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector_scaled.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff103453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fecea6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "evr = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44866f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0e19662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "LR is starting\n",
      "LR is trained\n",
      "LinearRegression()\n",
      "LinearRegression()\n",
      "['LR', 0.08718579061727871, 0.06357632602631243, 20111780.92337125, 19450039.85206186]\n",
      "LR is scored\n",
      "XGB is starting\n",
      "XGB is trained\n",
      "XGBRegressor(base_score=None, booster='gblinear', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=400, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "XGBRegressor(base_score=None, booster='gblinear', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=400, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=42, ...)\n",
      "['XGB', 0.08893049762456584, 0.06750537001219618, 20119886.54703823, 19451291.043312106]\n",
      "XGB is scored\n",
      "DTR is starting\n",
      "DTR is trained\n",
      "DecisionTreeRegressor(criterion='absolute_error', max_depth=5,\n",
      "                      min_samples_leaf=9, min_samples_split=8, random_state=42)\n",
      "DecisionTreeRegressor(criterion='absolute_error', max_depth=5,\n",
      "                      min_samples_leaf=9, min_samples_split=8, random_state=42)\n",
      "['DTR', 0.00033240654403317765, -0.025090981976295963, 21002429.502078444, 20835645.584152102]\n",
      "DTR is scored\n",
      "ADB is starting\n",
      "ADB is trained\n",
      "AdaBoostRegressor(learning_rate=0.01, random_state=42)\n",
      "AdaBoostRegressor(learning_rate=0.01, random_state=42)\n",
      "['ADB', 0.011715157807781429, -0.670158138351372, 19697628.00714482, 20565381.952816732]\n",
      "ADB is scored\n",
      "RIDGE is starting\n",
      "RIDGE is trained\n",
      "Ridge()\n",
      "Ridge()\n",
      "['RIDGE', 0.08724059664390382, 0.06386507335074654, 20111781.168374058, 19449769.30488558]\n",
      "RIDGE is scored\n",
      "LASSO is starting\n",
      "LASSO is trained\n",
      "LassoCV()\n",
      "LassoCV()\n",
      "['LASSO', 0.09378774072115204, 0.09398764937195762, 20153564.110562418, 19385405.065669425]\n",
      "LASSO is scored\n",
      "KNN is starting\n",
      "KNN is trained\n",
      "KNeighborsRegressor(algorithm='brute', n_neighbors=25, p=1)\n",
      "KNeighborsRegressor(algorithm='brute', n_neighbors=25, p=1)\n",
      "['KNN', 0.045732520411944644, 0.08715248865909249, 20651283.234290887, 20014776.850277703]\n",
      "KNN is scored\n",
      "GBR is starting\n",
      "GBR is trained\n",
      "GradientBoostingRegressor(learning_rate=0.01, max_depth=8, max_features='sqrt',\n",
      "                          min_samples_leaf=9, min_samples_split=8)\n",
      "GradientBoostingRegressor(learning_rate=0.01, max_depth=8, max_features='sqrt',\n",
      "                          min_samples_leaf=9, min_samples_split=8)\n",
      "['GBR', 0.06492915960235417, 0.059062985116918355, 17997850.22736507, 19937412.247378763]\n",
      "GBR is scored\n",
      "SVR is starting\n",
      "SVR is trained\n",
      "SVR(C=100, degree=4, epsilon=0.2)\n",
      "SVR(C=100, degree=4, epsilon=0.2)\n",
      "['SVR', -0.0016178325879145177, -0.004301878528526408, 21988839.936227437, 20872233.890601587]\n",
      "SVR is scored\n",
      "RFR is starting\n",
      "RFR is trained\n",
      "RandomForestRegressor(bootstrap=False, max_depth=100, max_features='sqrt',\n",
      "                      min_samples_leaf=4, min_samples_split=10,\n",
      "                      n_estimators=600, random_state=42)\n",
      "RandomForestRegressor(bootstrap=False, max_depth=100, max_features='sqrt',\n",
      "                      min_samples_leaf=4, min_samples_split=10,\n",
      "                      n_estimators=600, random_state=42)\n",
      "['RFR', 0.09506617278165719, 0.072826678051227, 12519975.343772598, 19506207.314092923]\n",
      "RFR is scored\n"
     ]
    }
   ],
   "source": [
    "model_selector_pca = model_selection(X_train_pca, y_train, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3546624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train acc</th>\n",
       "      <th>test acc</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.087186</td>\n",
       "      <td>0.063576</td>\n",
       "      <td>2.011178e+07</td>\n",
       "      <td>1.945004e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.088930</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>2.011989e+07</td>\n",
       "      <td>1.945129e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTR</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.025091</td>\n",
       "      <td>2.100243e+07</td>\n",
       "      <td>2.083565e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADB</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>-0.670158</td>\n",
       "      <td>1.969763e+07</td>\n",
       "      <td>2.056538e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.087241</td>\n",
       "      <td>0.063865</td>\n",
       "      <td>2.011178e+07</td>\n",
       "      <td>1.944977e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.093788</td>\n",
       "      <td>0.093988</td>\n",
       "      <td>2.015356e+07</td>\n",
       "      <td>1.938541e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.045733</td>\n",
       "      <td>0.087152</td>\n",
       "      <td>2.065128e+07</td>\n",
       "      <td>2.001478e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBR</td>\n",
       "      <td>0.064929</td>\n",
       "      <td>0.059063</td>\n",
       "      <td>1.799785e+07</td>\n",
       "      <td>1.993741e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.004302</td>\n",
       "      <td>2.198884e+07</td>\n",
       "      <td>2.087223e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RFR</td>\n",
       "      <td>0.095066</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>1.251998e+07</td>\n",
       "      <td>1.950621e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  train acc  test acc    train_rmse     test_rmse\n",
       "0     LR   0.087186  0.063576  2.011178e+07  1.945004e+07\n",
       "1    XGB   0.088930  0.067505  2.011989e+07  1.945129e+07\n",
       "2    DTR   0.000332 -0.025091  2.100243e+07  2.083565e+07\n",
       "3    ADB   0.011715 -0.670158  1.969763e+07  2.056538e+07\n",
       "4  RIDGE   0.087241  0.063865  2.011178e+07  1.944977e+07\n",
       "5  LASSO   0.093788  0.093988  2.015356e+07  1.938541e+07\n",
       "6    KNN   0.045733  0.087152  2.065128e+07  2.001478e+07\n",
       "7    GBR   0.064929  0.059063  1.799785e+07  1.993741e+07\n",
       "8    SVR  -0.001618 -0.004302  2.198884e+07  2.087223e+07\n",
       "9    RFR   0.095066  0.072827  1.251998e+07  1.950621e+07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector_pca.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7148fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeba4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pca = model_selector_pca.get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a965390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_svr = models_pca[\"SVR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8c6e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"Test_dataset_(2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "852a8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.rename(columns={\"Endoresed By\":\"Endorsed By\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b97c50b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_X_pp = preprocess(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4bc7d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_X_scaled = scaling(sub_X_pp, 0, sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd2aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_X_pca = pca.transform(sub_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8f5ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds = model_selector_pca.get_preds(\"SVR\", sub_X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fe0710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': LinearRegression(),\n",
       " 'XGB': XGBRegressor(base_score=None, booster='gblinear', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=400, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...),\n",
       " 'DTR': DecisionTreeRegressor(criterion='absolute_error', max_depth=5,\n",
       "                       min_samples_leaf=9, min_samples_split=8, random_state=42),\n",
       " 'ADB': AdaBoostRegressor(learning_rate=0.01, random_state=42),\n",
       " 'RIDGE': Ridge(),\n",
       " 'LASSO': LassoCV(),\n",
       " 'KNN': KNeighborsRegressor(algorithm='brute', n_neighbors=25, p=1),\n",
       " 'GBR': GradientBoostingRegressor(learning_rate=0.01, max_depth=8, max_features='sqrt',\n",
       "                           min_samples_leaf=9, min_samples_split=8),\n",
       " 'SVR': SVR(C=100, degree=4, epsilon=0.2),\n",
       " 'RFR': RandomForestRegressor(bootstrap=False, max_depth=100, max_features='sqrt',\n",
       "                       min_samples_leaf=4, min_samples_split=10,\n",
       "                       n_estimators=600, random_state=42)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector_pca.models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "322779a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Predictions\":sub_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bae32c84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions.to_csv(\"Submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a34c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_lasso = model_selector_pca.get_preds(\"LASSO\", sub_X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65cd06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_lasso})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2df9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"Submission_lasso.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "775308d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_dtr = model_selector_pca.get_preds(\"DTR\", sub_X_pca)\n",
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_dtr})\n",
    "predictions.to_csv(\"Submission_dtr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "599441b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_rfr = model_selector_pca.get_preds(\"RFR\", sub_X_pca)\n",
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_rfr})\n",
    "predictions.to_csv(\"Submission_rfr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b19d948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_ridge = model_selector_pca.get_preds(\"RIDGE\", sub_X_pca)\n",
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_ridge})\n",
    "predictions.to_csv(\"Submission_ridge.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49c5f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_sc_lasso = model_selector_scaled.get_preds(\"LASSO\", sub_X_scaled)\n",
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_sc_lasso})\n",
    "predictions.to_csv(\"Submission_sc_lasso.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cb06ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_sc_ridge = model_selector_scaled.get_preds(\"RIDGE\", sub_X_scaled)\n",
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_sc_ridge})\n",
    "predictions.to_csv(\"Submission_sc_ridge.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "575d74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_sc_xgb = model_selector_scaled.get_preds(\"XGB\", sub_X_scaled)\n",
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_sc_xgb})\n",
    "predictions.to_csv(\"Submission_sc_xgb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd162c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_preds_ac_lasso = model_selector.get_preds(\"LASSO\", sub_X_pp)\n",
    "predictions= pd.DataFrame({\"Registration Number\":list(sub_df[\"Registration Number\"]),\"Annual Turnover\":sub_preds_ac_lasso})\n",
    "predictions.to_csv(\"Submission_ac_lasso.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0fe5f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 65)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_X_pp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3698624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06eed265",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enum_type_wrapper' from 'google.protobuf.internal' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autodiff\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m app\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Generated by the protocol buffer compiler.  DO NOT EDIT!\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# source: tensorflow/core/framework/attr_value.proto\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"Generated protocol buffer code.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\builder.py:40\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"Builds descriptors, message classes and services for generated _pb2.py.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mThis file is only called in python generated _pb2.py files. It builds\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mdescriptors, message classes and services that users can directly use\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03min generated code.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjieluo@google.com (Jie Luo)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enum_type_wrapper\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m message \u001b[38;5;28;01mas\u001b[39;00m _message\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reflection \u001b[38;5;28;01mas\u001b[39;00m _reflection\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'enum_type_wrapper' from 'google.protobuf.internal' (unknown location)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assuming you have 65 features\n",
    "input_dim = 65\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer (input layer)\n",
    "model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Add three hidden layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "# Since it's a regression problem, we use linear activation function in the output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "# We use mean squared error loss function for regression problems\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Now your model is ready to be trained with your data using the fit method\n",
    "model.fit(X_train_pca, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57088399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
